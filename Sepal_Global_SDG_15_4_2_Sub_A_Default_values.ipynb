{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FWR5yMh0HV"
      },
      "source": [
        "# **SDG 15.4.2 Sub-indicator A: Calculate Global Default Values**\n",
        "\n",
        "* This script allows batch processing for this indicator for all countries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import ee\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from openpyxl.utils import get_column_letter\n",
        "from openpyxl.styles import Alignment\n",
        "from pathlib import Path\n",
        "\n",
        "from component.scripts.gee import reduce_regions\n",
        "from component.scripts.scripts import (\n",
        "    get_a_years,\n",
        "    get_reporting_years,\n",
        "    map_matrix_to_dict,\n",
        "    read_from_csv,\n",
        "    map_matrix_to_dict,\n",
        ")\n",
        "from component.scripts.colab_combining_files import (\n",
        "    sanitize_description,\n",
        "    append_excel_files,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEM_DEFAULT = \"CGIAR/SRTM90_V4\"\n",
        "\n",
        "# Define the translation matrix between ESA and MGCI LC classes\n",
        "\n",
        "LC_MAP_MATRIX = Path(\"content/corine_lc_map_matrix2.csv\")\n",
        "\n",
        "# Check they both exist\n",
        "assert LC_MAP_MATRIX.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t9C1qT5bGoqt"
      },
      "outputs": [],
      "source": [
        "admin_asset_id = \"projects/ee-xavidelamo/assets/M49Countries\"\n",
        "\n",
        "admin_asset_property_name = \"M49Name\"\n",
        "\n",
        "# For Sub-indicator A (sub_a), we need to set the following structure.\n",
        "a_years = {\n",
        "    1: {\"asset\": \"COPERNICUS/CORINE/V20/100m/2000\", \"year\": 2000}, \n",
        "    2: {\"year\": 2006, \"asset\": \"COPERNICUS/CORINE/V20/100m/2006\"}, \n",
        "    3: {\"year\": 2012, \"asset\": \"COPERNICUS/CORINE/V20/100m/2012\"},\n",
        "    4: {\"year\": 2018, \"asset\": \"COPERNICUS/CORINE/V20/100m/2018\"},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naz3Qe4JHFER"
      },
      "source": [
        "Output parameters\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the base directory\n",
        "base_dir = Path(\"content/sdg1542/sub_a\")\n",
        "base_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "mSvTM29TnndR"
      },
      "outputs": [],
      "source": [
        "csv_path = base_dir/\"raw_stats\"\n",
        "raw_reports = base_dir/\"raw_reports\"\n",
        "final_report = base_dir/\"final_report\"\n",
        "\n",
        "error_log_file_path = base_dir / \"error_log.csv\"\n",
        "\n",
        "final_report_file_path = final_report / \"final_report.xlsx\"\n",
        "\n",
        "# Create the directories\n",
        "csv_path.mkdir(parents=True, exist_ok=True)\n",
        "raw_reports.mkdir(parents=True, exist_ok=True)\n",
        "final_report.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "export = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi5zNGTWN3df"
      },
      "source": [
        "Create list of boundaries to process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiuBEJwPue2v"
      },
      "outputs": [],
      "source": [
        "# admin boundary feature collection\n",
        "admin_boundaries = ee.FeatureCollection(admin_asset_id)\n",
        "\n",
        "# list to process\n",
        "list_of_countries = admin_boundaries.aggregate_array(admin_asset_property_name).getInfo()\n",
        "\n",
        "print (\"Length of admin boundaries to process\", len(list_of_countries))\n",
        "\n",
        "list_of_countries = list(set(list_of_countries)) # remove dupicates\n",
        "\n",
        "print (\"Length of distinct admin boundaries to process\", (len(set(list_of_countries))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PRSEqq5bu_f7"
      },
      "outputs": [],
      "source": [
        "default_map_matrix = map_matrix_to_dict(LC_MAP_MATRIX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate tasks in GEE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VftKLuY4u_f7"
      },
      "outputs": [],
      "source": [
        "counter=0 # starting place of counter used to keep track of number of tasks that are being run\n",
        "\n",
        "for aoi_name in list_of_countries:\n",
        "\n",
        "    aoi = admin_boundaries.filter(ee.Filter.eq(admin_asset_property_name,aoi_name))\n",
        "\n",
        "    # gets areas of landcover in each mountain belt in each country\n",
        "    # uses reduce_regions function imported from the cloned sepal_mgci git hub repository (see Imports section)\n",
        "    # pixels counted at native resolution (scale) of input land cover (or DEM if RSA implementation)\n",
        "    process = ee.FeatureCollection([\n",
        "        ee.Feature(\n",
        "            None,\n",
        "            reduce_regions(\n",
        "                aoi,\n",
        "                remap_matrix=default_map_matrix,\n",
        "                rsa=False,\n",
        "                dem=DEM_DEFAULT, #default digital elevation model (DEM). Relevant for the real surface area (RSA) implementation.\n",
        "                lc_years= year,\n",
        "                transition_matrix=False\n",
        "            )\n",
        "        ).set(\"process_id\", year[0][\"year\"])\n",
        "        for year in get_a_years(a_years) # creates GEE images and runs stats on each. Images to run are in the 'a_years\" dictionary (above)\n",
        "    ])\n",
        "\n",
        "    #make name acceptable for running tasks (i.e., removes special characters)\n",
        "    task_name = str(sanitize_description(aoi_name))\n",
        "\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        **{  #asterisks unpack dictionary into keyword arguments format\n",
        "            \"collection\": process,\n",
        "            \"description\": task_name,\n",
        "            \"fileFormat\": \"CSV\",\n",
        "            \"folder\":\"sdg1542/sub_a/raw_stats\",\n",
        "            \"selectors\": [\n",
        "                \"process_id\",\n",
        "                \"sub_a\",\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    counter+=1\n",
        "\n",
        "    print (f\"\\r process {counter}/{len(list_of_countries)} {aoi_name} \", end=\"\") #print in place (remove \\r and end=\"\" for verbose version)\n",
        "\n",
        "    if export:\n",
        "      task.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM0SIvJtu_f8"
      },
      "source": [
        "# Read in and translate results into report tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkpDfHqQu_f9"
      },
      "outputs": [],
      "source": [
        "from component.scripts.scripts import get_sub_a_data_reports\n",
        "\n",
        "counter = 0\n",
        "\n",
        "# Loop over each AOI name in the list of countries\n",
        "for stats_csv_file_path in csv_path.glob(\"[!.]*.csv\"):\n",
        "    counter += 1\n",
        "    aoi_name = stats_csv_file_path.stem.replace(\"_sepal\", \"\")\n",
        "\n",
        "    # # Clean the AOI name\n",
        "    aoi_name_clean = str(sanitize_description(aoi_name))\n",
        "\n",
        "    message = f\"Process {counter}, {stats_csv_file_path}\"\n",
        "\n",
        "    try:\n",
        "        # Read the results from the CSV file and parse it to a dictionary\n",
        "        results = read_from_csv(stats_csv_file_path)\n",
        "        reporting_years_sub_a = get_reporting_years(a_years, \"sub_a\")\n",
        "        details = {\n",
        "            \"geo_area_name\": aoi_name,\n",
        "            \"ref_area\": \" \",\n",
        "            \"source_detail\": \" \",\n",
        "        }\n",
        "\n",
        "        sub_a_reports, mtn_reports = get_sub_a_data_reports(\n",
        "            results, reporting_years_sub_a, **details\n",
        "        )\n",
        "\n",
        "        # Concatenate the mtn reports\n",
        "        mtn_reports_df = pd.concat(mtn_reports)\n",
        "\n",
        "        # Concatenate the sub a reports\n",
        "        er_mtn_grnvi_df = pd.concat([report[0] for report in sub_a_reports])\n",
        "        er_mtn_grncov_df = pd.concat([report[1] for report in sub_a_reports])\n",
        "\n",
        "        # Define the output report file path\n",
        "        report_file_path = raw_reports / f\"{aoi_name_clean}.xlsx\"\n",
        "\n",
        "        # Create the Excel file with the reports\n",
        "        with pd.ExcelWriter(report_file_path) as writer:\n",
        "            mtn_reports_df.to_excel(\n",
        "                writer, sheet_name=\"Table1_ER_MTN_TOTL\", index=False\n",
        "            )\n",
        "            er_mtn_grncov_df.to_excel(\n",
        "                writer, sheet_name=\"Table2_ER_MTN_GRNCOV\", index=False\n",
        "            )\n",
        "            er_mtn_grnvi_df.to_excel(\n",
        "                writer, sheet_name=\"Table3_ER_MTN_GRNCVI\", index=False\n",
        "            )\n",
        "\n",
        "            # Adjust column widths and alignment for each sheet\n",
        "            for sheetname in writer.sheets:\n",
        "                worksheet = writer.sheets[sheetname]\n",
        "                for col in worksheet.columns:\n",
        "                    max_length = max(len(str(cell.value)) for cell in col)\n",
        "                    column = col[0]\n",
        "                    adjusted_width = max(max_length, len(str(column.value))) + 4\n",
        "                    worksheet.column_dimensions[\n",
        "                        get_column_letter(column.column)\n",
        "                    ].width = adjusted_width\n",
        "\n",
        "                    # Align \"obs_value\" column to the right\n",
        "                    if \"OBS\" in column.value:\n",
        "                        for cell in col:\n",
        "                            cell.alignment = Alignment(horizontal=\"right\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # If an error occurs, catch the exception and handle it\n",
        "        message = f\"process {counter}, {stats_csv_file_path.stem}, Error: {e}\"\n",
        "\n",
        "        # Get the current time\n",
        "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Write the error message and file name to the error log file\n",
        "        error_info = pd.DataFrame(\n",
        "            [[stats_csv_file_path.stem, str(e), current_time]],\n",
        "            columns=[\"File Name\", \"Error Message\", \"Time\"],\n",
        "        )\n",
        "\n",
        "        mode = \"w\" if not os.path.exists(error_log_file_path) else \"a\"\n",
        "        header = False if os.path.exists(error_log_file_path) else True\n",
        "\n",
        "        # Append or write to the error log file\n",
        "        error_info.to_csv(error_log_file_path, mode=mode, header=header, index=False)\n",
        "\n",
        "\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTqI3Ag08k5b"
      },
      "source": [
        "### 10) Combine excel report files into one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVpLtG4Z7Jbe"
      },
      "source": [
        "Make a list of files to combine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTyhwne7rr9D"
      },
      "outputs": [],
      "source": [
        "raw_reports_files = list(raw_reports.glob(\"[!.]*.xlsx\"))\n",
        "\n",
        "# Print the number of Excel files found in the folder\n",
        "print(f\"Number of Excel files in folder: {len(list(raw_reports_files))}\")\n",
        "\n",
        "append_excel_files(file_paths=raw_reports_files,num_sheets=3,output_file_path=str(final_report_file_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C77flAQu7xWX"
      },
      "source": [
        "##### Run function to combine into a single report"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "(test) test-sepal_mgci",
      "language": "python",
      "name": "test-sepal_mgci"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
